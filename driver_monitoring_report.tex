\documentclass[12pt]{article}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{enumitem}
\geometry{a4paper, margin=0.7in}

\usepackage{hyperref}
\usepackage{tikz}

\begin{document}

% Title page with large margins
{\newgeometry{left=1in,right=1in,top=1.2in,bottom=1.2in}
\begin{titlepage}
    \centering
    \vspace{1cm}
    {\Large\scshape James Madison University \par}
    \vspace{0.5cm}
    {\large Information Technology (IT) Program \par}
    {\large IT 445 - Capstone Implementation \par}
    {\large Spring 2023 \par}
    \vspace{1cm}
    \rule{\textwidth}{0.5pt}
    \vspace{0.5cm}
    {\bfseries\LARGE Analyzing Autonomous Cart Passenger\\[0.2cm]
    Experience Using Emotion Detection \par}
    \vspace{0.5cm}
    \rule{\textwidth}{0.5pt}
    \vspace{0.8cm}
    {\large Monday 30\textsuperscript{th} June, 2025 \par}
    {\large 12:22:50 \par}
    \vspace{0.5cm}
    \begin{minipage}{0.3\textwidth}
        \raggedright
        \textit{Submitted to:}\\
        Dr. Samy El-Tawab
    \end{minipage}
    \begin{minipage}{0.45\textwidth}
        \raggedleft
        \textit{Authors:}\\
        Rana Moussa \par Ramez Asaad
    \end{minipage}
    \vfill
    % Optionally add logos here
    % \includegraphics[width=0.35\textwidth]{jmu_logo.png}\par
    % \vspace{1cm}
    % \includegraphics[width=0.18\textwidth]{jac_logo.png}\par
    % \vspace{1cm}
\end{titlepage}
\restoregeometry}

% Set smaller margins for the rest of the document
\geometry{a4paper, margin=0.7in}

\section{Introduction}
This project implements a real-time driver monitoring system using computer vision and deep learning. The system analyzes facial expressions, eye and mouth movements, and head posture to detect emotional and physical states such as drowsiness, yawning, head nodding, and emotions like sadness, fear, and neutrality. Based on these inputs, the system can be integrated with an external control mechanism to adjust the speed of a cart, slowing down in unsafe conditions and maintaining speed when the driver appears attentive.
\usetikzlibrary{shapes.geometric, arrows.meta}

\usetikzlibrary{matrix, positioning, arrows.meta}

\begin{tikzpicture}[
  block/.style={rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm, text centered, draw=black, fill=blue!10},
  arrow/.style={thick,->,>=Stealth}
]
\matrix (m) [row sep=1cm, column sep=1.5cm] {
  % Row 1
  \node[block] (input) {Camera Frame Capture}; & \\
  % Row 2
  \node[block] (preprocess) {Frame Preprocessing (BGR $\rightarrow$ RGB)}; & \\
  % Row 3
  \node[block] (landmarks) {Face Detection \& Landmark Extraction (MediaPipe)}; & \node[block] (fatigue) {Fatigue \& Alertness Analysis}; \\
  % Row 4
  \node[block] (crop) {Per-Face Cropping}; & \\
  % Row 5
  \node[block] (deepface) {Emotion Analysis (DeepFace)}; & \\
  % Row 6
  \node[block] (correction) {Emotion Correction \& Smoothing}; & \\
  % Row 7
  \node[block] (output) {Visualization \& Output}; & \\
};

\draw[arrow] (input) -- (preprocess);
\draw[arrow] (preprocess) -- (landmarks);
\draw[arrow] (landmarks) -- (crop);
\draw[arrow] (crop) -- (deepface);
\draw[arrow] (deepface) -- (correction);
\draw[arrow] (correction) -- (output);
\draw[arrow] (landmarks) -- (fatigue);
\draw[arrow] (fatigue) |- (correction);
\end{tikzpicture}

\section{Project Goals}
\begin{itemize}
    \item Detect multiple faces simultaneously and analyze their states independently.
    \item Recognize driver tiredness indicators such as eye blinks, yawns, and head nodding.
    \item Detect and classify driver emotions in real-time using DeepFace and MediaPipe.
    \item Correct misclassifications (e.g., treat fear as neutral when indicators don’t match).
    \item Provide a safety mechanism by interpreting emotional and physical states for vehicle speed control (hypothetically adjusting cart speed).
\end{itemize}

\section{Technologies Used}
\begin{itemize}
    \item \textbf{OpenCV}: For real-time webcam video capture and frame processing.
    \item \textbf{MediaPipe}: For precise face landmark detection (eyes, mouth, nose).
    \item \textbf{DeepFace}: For emotion analysis using a deep learning model.
    \item \textbf{NumPy}: For numerical operations like distance calculations.
    \item \textbf{Python}: The overall implementation language.
    \item \textbf{Collections (deque, defaultdict)}: For maintaining per-face history and state.
\end{itemize}

\section{Core Functionality}
\subsection{Face Landmark Detection (MediaPipe)}
\begin{itemize}
    \item Tracks up to 5 faces simultaneously.
    \item Extracts key facial landmarks for eyes, mouth, and nose.
\end{itemize}
\subsection{Emotion Detection (DeepFace)}
\begin{itemize}
    \item Captures a cropped face image and predicts the dominant emotion.
    \item Applies smoothing to avoid flickering or unstable predictions.
    \item Includes logic to override fear or sad when facial context contradicts it.
\end{itemize}
\subsection{Tiredness Detection}
\begin{itemize}
    \item Eye Aspect Ratio (EAR) detects blinking or eye closure.
    \item Mouth Aspect Ratio (MAR) detects yawning.
    \item A sustained low EAR triggers a drowsiness warning.
    \item A high MAR triggers a yawning warning.
\end{itemize}
\subsection{Head Nod Detection}
\begin{itemize}
    \item Compares vertical displacement of the nose tip across frames.
    \item Large vertical shifts indicate nodding, a sign of sleepiness.
\end{itemize}
\subsection{Emotion Correction Rules}
\begin{itemize}
    \item Emotion `fear` downgraded to `neutral` if facial features are calm.
    \item Emotion `sad` reclassified if mouth corners are raised or EAR is high.
    \item Uses a rolling emotion history to ensure stability before updating UI.
\end{itemize}
\subsection{Visual Output}
\begin{itemize}
    \item Displays:
    \begin{itemize}
        \item Real-time bounding box around each face.
        \item Emotion label above the face.
        \item Warnings such as ``\textbf{⚠ Drowsiness}'', ``\textbf{⚠ Yawning}''